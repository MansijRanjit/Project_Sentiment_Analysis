{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting codeswitchNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading codeswitch-1.1-py3-none-any.whl (4.1 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.29.0-py3-none-any.whl (7.1 MB)\n",
      "     ---------------------------------------- 7.1/7.1 MB 112.7 kB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     ------------------------------------ 224.5/224.5 kB 402.7 kB/s eta 0:00:00\n",
      "Collecting numpy>=1.17\n",
      "  Downloading numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "     -------------------------------------- 14.8/14.8 MB 262.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from transformers->codeswitch) (23.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp311-cp311-win_amd64.whl (143 kB)\n",
      "     ------------------------------------ 143.2/143.2 kB 137.2 kB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.5.5-cp311-cp311-win_amd64.whl (267 kB)\n",
      "     ------------------------------------ 267.9/267.9 kB 294.5 kB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
      "     -------------------------------------- 62.5/62.5 kB 257.4 kB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 485.5 kB/s eta 0:00:00\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "     -------------------------------------- 77.1/77.1 kB 718.9 kB/s eta 0:00:00\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "     ------------------------------------ 160.1/160.1 kB 738.1 kB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: colorama in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from tqdm>=4.27->transformers->codeswitch) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp311-cp311-win_amd64.whl (96 kB)\n",
      "     -------------------------------------- 96.7/96.7 kB 793.1 kB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "     -------------------------------------- 61.5/61.5 kB 657.7 kB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
      "     ------------------------------------ 123.2/123.2 kB 807.2 kB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "     ------------------------------------ 157.0/157.0 kB 468.8 kB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, urllib3, typing-extensions, tqdm, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, transformers, codeswitch\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.1.0 codeswitch-1.1 filelock-3.12.0 fsspec-2023.5.0 huggingface-hub-0.14.1 idna-3.4 numpy-1.24.3 pyyaml-6.0 regex-2023.5.5 requests-2.30.0 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.29.0 typing-extensions-4.5.0 urllib3-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/filelock/\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/ad/73/b094a662ae05cdc4ec95bc54e434e307986a5de5960166b8161b7c1373ee/filelock-3.12.0-py3-none-any.whl\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install codeswitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pretrained model. It will take time according to model size and your internet speed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 49.0/49.0 [00:00<?, ?B/s]\n",
      "e:\\Project Sentiment analysis\\projenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 933/933 [00:00<00:00, 936kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 996k/996k [00:00<00:00, 1.20MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 112kB/s]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForTokenClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcodeswitch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcodeswitch\u001b[39;00m \u001b[39mimport\u001b[39;00m LanguageIdentification\n\u001b[1;32m----> 2\u001b[0m lid \u001b[39m=\u001b[39m LanguageIdentification(\u001b[39m'\u001b[39;49m\u001b[39mnep-eng\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhello k xa\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m result\u001b[39m=\u001b[39mlid\u001b[39m.\u001b[39midentify(text)\n",
      "File \u001b[1;32me:\\Project Sentiment analysis\\projenv\\Lib\\site-packages\\codeswitch\\codeswitch.py:19\u001b[0m, in \u001b[0;36mLanguageIdentification.__init__\u001b[1;34m(self, language)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDownloading pretrained model. It will take time according to model size and your internet speed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39msagorsarker/codeswitch-nepeng-lid-lince\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m AutoModelForTokenClassification\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39msagorsarker/codeswitch-nepeng-lid-lince\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mModel Download Completed!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Project Sentiment analysis\\projenv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1112\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_from_config\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1112\u001b[0m requires_backends(\u001b[39mcls\u001b[39;49m, \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_backends)\n",
      "File \u001b[1;32me:\\Project Sentiment analysis\\projenv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1100\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1098\u001b[0m failed \u001b[39m=\u001b[39m [msg\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m available, msg \u001b[39min\u001b[39;00m checks \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m available()]\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m failed:\n\u001b[1;32m-> 1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nAutoModelForTokenClassification requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from codeswitch.codeswitch import LanguageIdentification\n",
    "lid = LanguageIdentification('nep-eng')\n",
    "text=\"hello k xa\"\n",
    "result=lid.identify(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcodeswitch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcodeswitch\u001b[39;00m \u001b[39mimport\u001b[39;00m LanguageIdentification\n\u001b[0;32m      3\u001b[0m lid \u001b[39m=\u001b[39m LanguageIdentification(\u001b[39m'\u001b[39m\u001b[39mnep-eng\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from codeswitch.codeswitch import LanguageIdentification\n",
    "lid = LanguageIdentification('nep-eng')\n",
    "text=\"hello k xa\"\n",
    "result=lid.identify(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3060902485.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
