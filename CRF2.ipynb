{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in e:\\project sentiment analysis\\projenv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def readCorpus(fpath):\n",
    "    sents = []\n",
    "    with open(fpath) as fd:\n",
    "        sent = []\n",
    "        for l in fd:\n",
    "            #lt = l.strip().decode(\"utf8\")\n",
    "            lt = l.strip()\n",
    "            if not lt:\n",
    "                sents.append(sent)\n",
    "                sent = []\n",
    "            else:\n",
    "                w_t = lt.split('\\t')\n",
    "                sent.append([w_t[0], w_t[1]])\n",
    "    return sents\n",
    "\n",
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = [\n",
    "        #'bias',\n",
    "        'word.lower=' + word.lower(),\n",
    "        #'word[-3:]=' + word[-3:],\n",
    "        #'word[-2:]=' + word[-2:],\n",
    "        #'word.isupper=%s' % word.isupper(),\n",
    "        #'word.istitle=%s' % word.istitle(),\n",
    "        #'word.isdigit=%s' % word.isdigit(),\n",
    "        'postag=' + postag,\n",
    "        #'postag[:2]=' + postag[:2],\n",
    "    ]\n",
    "    if i > 0:\n",
    "        pass\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.extend([\n",
    "            '-1:word.lower=' + word1.lower(),\n",
    "            #'-1:word.istitle=%s' % word1.istitle(),\n",
    "            #'-1:word.isupper=%s' % word1.isupper(),\n",
    "            '-1:postag=' + postag1,\n",
    "            #'-1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('BOS')\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        pass\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.extend([\n",
    "            '+1:word.lower=' + word1.lower(),\n",
    "            #'+1:word.istitle=%s' % word1.istitle(),\n",
    "            #'+1:word.isupper=%s' % word1.isupper(),\n",
    "            '+1:postag=' + postag1,\n",
    "            #'+1:postag[:2]=' + postag1[:2],\n",
    "        ])\n",
    "    else:\n",
    "        features.append('EOS')\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start append train set.\n",
      "append train set done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x18f73619550>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = readCorpus(\"CrfTrain.TXT\")\n",
    "#print(train_sents)\n",
    "x_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "#print(y_train)\n",
    "\n",
    "print(\"start append train set.\")\n",
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(x_train, y_train):\n",
    "    trainer.append(xseq, yseq)\n",
    "print(\"append train set done.\")\n",
    "trainer.set_params({\n",
    "    'c1': 1.0,\n",
    "    'c2': 1e-3,\n",
    "    'max_iterations': 500,\n",
    "    'feature.possible_transitions': True\n",
    "    })\n",
    "\n",
    "trainer.train(\"trained_model\")\n",
    "test_object = pycrfsuite.Tagger()\n",
    "test_object.open(\"trained_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same as picture but string chahi ali moto cha but nice quality\n",
      "\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ENG', 'O']\n",
      "Predicted: O O O O O O O O O O B-ENG O\n",
      "Correct:   O O O O O O O O O O B-ENG O\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ENG       1.00      1.00      1.00       265\n",
      "       I-ENG       1.00      1.00      1.00        84\n",
      "       B-NEG       1.00      1.00      1.00        62\n",
      "       I-NEG       1.00      1.00      1.00        10\n",
      "       B-POS       1.00      1.00      1.00       211\n",
      "       I-POS       1.00      1.00      1.00        58\n",
      "           o       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       692\n",
      "   macro avg       1.00      1.00      1.00       692\n",
      "weighted avg       1.00      1.00      1.00       692\n",
      " samples avg       0.21      0.21      0.21       692\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Project Sentiment analysis\\projenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "e:\\Project Sentiment analysis\\projenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Test on the first sentence of the training data\n",
    "#First load the trained model\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('trained_model')\n",
    "\n",
    "#Read the first sentence\n",
    "#print(train_sents[0])\n",
    "example_sent = train_sents[0]\n",
    "print(' '.join(sent2tokens(example_sent)), end='\\n\\n')\n",
    "print(sent2labels(example_sent))\n",
    "\n",
    "#Predict and test\n",
    "print(\"Predicted:\", ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print(\"Correct:  \", ' '.join(sent2labels(example_sent)))\n",
    "\n",
    "#This will give you the precision, recall, F-score\n",
    "def sentiment_classification_report(y_true, y_pred):\n",
    " \n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "##Evaluation of the labeller\n",
    "y_pred = [tagger.tag(xseq) for xseq in x_train]\n",
    "print(sentiment_classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo', 'product', 'malai', 'ramro', 'lagyo']\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(file_path):\n",
    "    words=[]  # List to store the words\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            line_words = line.split()  # Split line into individual words\n",
    "            for word in line_words:\n",
    "                words.append(word)  # Add words to the list\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "file_path = \"E:/Project Sentiment analysis/CRF/xyz.txt\"  # Path to the text file\n",
    "\n",
    "# Read the text file and store words in a list\n",
    "word_list = read_text_file(file_path)\n",
    "print(word_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo', 'product', 'malai', 'ramro', 'lagyo']\n",
      "['o', 'B-POS', 'I-POS', 'B-POS', 'I-POS']\n",
      "Predicted: o B-POS I-POS B-POS I-POS\n",
      "Positive Sentiment Count=4\n",
      "Negative Sentiment Count=0\n"
     ]
    }
   ],
   "source": [
    "#Test on the test data \n",
    "#First load the trained model\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('trained_model')\n",
    "\n",
    "#Predict and test\n",
    "print(word_list)\n",
    "\n",
    "# example=[]\n",
    "# example.append((\"hi\"))\n",
    "# print(example)\n",
    "\n",
    "feature=sent2features(word_list)\n",
    "#print(feature)\n",
    "lab=tagger.tag(feature)\n",
    "print(lab)\n",
    "print(\"Predicted:\", ' '.join(lab))\n",
    "\n",
    "PosCount=0\n",
    "NegCount=0\n",
    "for i in lab:\n",
    "    if(i==\"B-POS\" or i==\"I-POS\"):\n",
    "        PosCount+=1\n",
    "    elif(i==\"B-NEG\" or i==\"I-NEG\"):\n",
    "        NegCount+=1\n",
    "print(f\"Positive Sentiment Count={PosCount}\")\n",
    "print(f\"Negative Sentiment Count={NegCount}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
