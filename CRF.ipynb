{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in e:\\project sentiment analysis\\projenv\\lib\\site-packages (0.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in e:\\project sentiment analysis\\projenv\\lib\\site-packages (1.24.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post5.tar.gz (3.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: sklearn\n",
      "  Running setup.py install for sklearn: started\n",
      "  Running setup.py install for sklearn: finished with status 'done'\n",
      "Successfully installed sklearn-0.0.post5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: sklearn is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from sklearn-crfsuite) (0.9.9)\n",
      "Requirement already satisfied: six in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from sklearn-crfsuite) (1.16.0)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: tqdm>=2.0 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from sklearn-crfsuite) (4.65.0)\n",
      "Requirement already satisfied: colorama in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite) (0.4.6)\n",
      "Installing collected packages: tabulate, sklearn-crfsuite\n",
      "Successfully installed sklearn-crfsuite-0.3.6 tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-crfsuite in e:\\project sentiment analysis\\projenv\\lib\\site-packages (0.9.9)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "     ------------------------------------- 250.0/250.0 kB 40.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in e:\\project sentiment analysis\\projenv\\lib\\site-packages (3.8.1)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: click in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from nltk) (2023.5.5)\n",
      "Requirement already satisfied: tqdm in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in e:\\project sentiment analysis\\projenv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-crfsuite openpyxl nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import nltk\n",
    "\n",
    "def extract_features(tokens):\n",
    "    features = []\n",
    "    for i in range(len(tokens)):\n",
    "        word = tokens[i]\n",
    "        features.append({\n",
    "            'word': word,\n",
    "         #   'pos': nltk.pos_tag([word])[0][1],\n",
    "        })\n",
    "    return features\n",
    "\n",
    "def extract_labels(data):\n",
    "    return [label for _, label in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_excel(file_path):\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    data = []\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        token = row[0]\n",
    "        label = row[1]\n",
    "        data.append((token, label))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "\n",
    "def train_crf_model(train_data, feature_extractor, label_extractor, model_path):\n",
    "    trainer = pycrfsuite.Trainer(verbose=False)\n",
    "    for tokens, labels in train_data:\n",
    "        features = feature_extractor(tokens)\n",
    "        trainer.append(features, labels)\n",
    "\n",
    "    trainer.set_params({\n",
    "        'c1': 1.0,   # coefficient for L1 penalty\n",
    "        'c2': 1e-3,  # coefficient for L2 penalty\n",
    "        'max_iterations': 100,  # maximum number of iterations\n",
    "        'feature.possible_transitions': True  # include transitions that are possible, but not observed\n",
    "    })\n",
    "    \n",
    "    trainer.train(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_crf_model(test_data, feature_extractor, label_extractor, model_path):\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(model_path)\n",
    "\n",
    "    predictions = []\n",
    "    for tokens, _ in test_data:\n",
    "        features = feature_extractor(tokens)\n",
    "        pred_labels = tagger.tag(features)\n",
    "        predictions.append(pred_labels)\n",
    "\n",
    "    true_labels = [label_extractor(data) for data in test_data]\n",
    "\n",
    "    return true_labels, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3596\n",
      "3596\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_labels))\n\u001b[0;32m     11\u001b[0m \u001b[39m# Perform any necessary preprocessing on the tokens and labels\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m train_crf_model(\u001b[39mzip\u001b[39;49m(train_tokens, train_labels), extract_features, extract_labels, model_path)\n",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m, in \u001b[0;36mtrain_crf_model\u001b[1;34m(train_data, feature_extractor, label_extractor, model_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m trainer \u001b[39m=\u001b[39m pycrfsuite\u001b[39m.\u001b[39mTrainer(verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m tokens, labels \u001b[39min\u001b[39;00m train_data:\n\u001b[1;32m----> 6\u001b[0m     features \u001b[39m=\u001b[39m feature_extractor(tokens)\n\u001b[0;32m      7\u001b[0m     trainer\u001b[39m.\u001b[39mappend(features, labels)\n\u001b[0;32m      9\u001b[0m trainer\u001b[39m.\u001b[39mset_params({\n\u001b[0;32m     10\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mc1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1.0\u001b[39m,   \u001b[39m# coefficient for L1 penalty\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mc2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m1e-3\u001b[39m,  \u001b[39m# coefficient for L2 penalty\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_iterations\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m100\u001b[39m,  \u001b[39m# maximum number of iterations\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfeature.possible_transitions\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m  \u001b[39m# include transitions that are possible, but not observed\u001b[39;00m\n\u001b[0;32m     14\u001b[0m })\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_features\u001b[39m(tokens):\n\u001b[0;32m      5\u001b[0m     features \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(tokens)):\n\u001b[0;32m      7\u001b[0m         word \u001b[39m=\u001b[39m tokens[i]\n\u001b[0;32m      8\u001b[0m         features\u001b[39m.\u001b[39mappend({\n\u001b[0;32m      9\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m: word,\n\u001b[0;32m     10\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mpos\u001b[39m\u001b[39m'\u001b[39m: nltk\u001b[39m.\u001b[39mpos_tag([word])[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m],\n\u001b[0;32m     11\u001b[0m         })\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train_file = 'Nepali_Romanized_Sentiment.xlsx'\n",
    "model_path = 'sentiment_model.crfsuite'\n",
    "\n",
    "# Load and preprocess the training data\n",
    "train_data = read_data_from_excel(train_file)\n",
    "print(len(train_data))\n",
    "# Split the data into tokens and labels\n",
    "train_tokens, train_labels = zip(*train_data)\n",
    "print(len(train_labels))\n",
    "\n",
    "# Perform any necessary preprocessing on the tokens and labels\n",
    "\n",
    "# Train the model\n",
    "train_crf_model(zip(train_tokens, train_labels), extract_features, extract_labels, model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
